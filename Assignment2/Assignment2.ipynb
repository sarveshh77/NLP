{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# NLP Lab: Bag-of-Words, TF-IDF, and **Word2Vec**"
      ],
      "metadata": {
        "id": "N4K-vLK6zVhj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install nltk scikit-learn gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHVQKlidzXCS",
        "outputId": "650580cd-d865-4346-bd63-a0e5a21b9447"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Collecting gensim\n",
            "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n",
            "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gensim\n",
            "Successfully installed gensim-4.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9H5swaWzZi1",
        "outputId": "9b4a2a1c-3a65-4cb1-91f9-4d93ce7e7a87"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sample **Dataset**"
      ],
      "metadata": {
        "id": "9PJZ163UzvpR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documents = [\n",
        "    \"I love natural language processing\",\n",
        "    \"Natural language processing is very interesting\",\n",
        "    \"I love learning NLP concepts\"\n",
        "]\n",
        "\n",
        "print(\"Documents:\")\n",
        "for doc in documents:\n",
        "    print(\"-\", doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9WEkls6zeZL",
        "outputId": "981c40af-f09b-460b-e5e0-267cc76f5180"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Documents:\n",
            "- I love natural language processing\n",
            "- Natural language processing is very interesting\n",
            "- I love learning NLP concepts\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bag of Words – Count **Occurrence**"
      ],
      "metadata": {
        "id": "76HlaxuKz1Ar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count_vectorizer = CountVectorizer()\n",
        "bow_counts = count_vectorizer.fit_transform(documents)\n",
        "\n",
        "print(\"Vocabulary:\", count_vectorizer.get_feature_names_out())\n",
        "print(\"BoW Count Matrix:\\n\", bow_counts.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6F4vBP-ztkV",
        "outputId": "fea643d8-79ba-400b-8fe7-40decffcfeca"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary: ['concepts' 'interesting' 'is' 'language' 'learning' 'love' 'natural'\n",
            " 'nlp' 'processing' 'very']\n",
            "BoW Count Matrix:\n",
            " [[0 0 0 1 0 1 1 0 1 0]\n",
            " [0 1 1 1 0 0 1 0 1 1]\n",
            " [1 0 0 0 1 1 0 1 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bag of Words – Normalized Count **Occurrence**"
      ],
      "metadata": {
        "id": "R3dj0GDZz6MC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "# Step 1: Count Occurrence\n",
        "count_vectorizer = CountVectorizer()\n",
        "bow_counts = count_vectorizer.fit_transform(documents)\n",
        "\n",
        "print(\"Vocabulary:\", count_vectorizer.get_feature_names_out())\n",
        "print(\"BoW Count Matrix:\\n\", bow_counts.toarray())\n",
        "\n",
        "# Step 2: Normalized Count Occurrence (L2 normalization)\n",
        "bow_normalized = normalize(bow_counts, norm='l2')\n",
        "\n",
        "print(\"Normalized BoW Matrix:\\n\", bow_normalized.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTwJD2Upz4TD",
        "outputId": "28946042-71e6-4222-9584-9ebb470af5e7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary: ['concepts' 'interesting' 'is' 'language' 'learning' 'love' 'natural'\n",
            " 'nlp' 'processing' 'very']\n",
            "BoW Count Matrix:\n",
            " [[0 0 0 1 0 1 1 0 1 0]\n",
            " [0 1 1 1 0 0 1 0 1 1]\n",
            " [1 0 0 0 1 1 0 1 0 0]]\n",
            "Normalized BoW Matrix:\n",
            " [[0.         0.         0.         0.5        0.         0.5\n",
            "  0.5        0.         0.5        0.        ]\n",
            " [0.         0.40824829 0.40824829 0.40824829 0.         0.\n",
            "  0.40824829 0.         0.40824829 0.40824829]\n",
            " [0.5        0.         0.         0.         0.5        0.5\n",
            "  0.         0.5        0.         0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TF-**IDF**"
      ],
      "metadata": {
        "id": "TyZrXOfuz__3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n",
        "\n",
        "print(\"Vocabulary:\", tfidf_vectorizer.get_feature_names_out())\n",
        "print(\"TF-IDF Matrix:\\n\", tfidf_matrix.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mI7wikHz9YC",
        "outputId": "4fbd47b2-b486-4b4d-8b1f-72ee62a52bcd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary: ['concepts' 'interesting' 'is' 'language' 'learning' 'love' 'natural'\n",
            " 'nlp' 'processing' 'very']\n",
            "TF-IDF Matrix:\n",
            " [[0.         0.         0.         0.5        0.         0.5\n",
            "  0.5        0.         0.5        0.        ]\n",
            " [0.         0.45954803 0.45954803 0.34949812 0.         0.\n",
            "  0.34949812 0.         0.34949812 0.45954803]\n",
            " [0.52863461 0.         0.         0.         0.52863461 0.40204024\n",
            "  0.         0.52863461 0.         0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word2Vec **Embeddings**"
      ],
      "metadata": {
        "id": "1tKboMTE0HcG"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85fd3432",
        "outputId": "1bb82ec4-fbd9-4633-db4a-1e96b33cd0cc"
      },
      "source": [
        "nltk.download('punkt_tab')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize sentences\n",
        "tokenized_docs = [word_tokenize(doc.lower()) for doc in documents]\n",
        "\n",
        "\n",
        "w2v_model = Word2Vec(\n",
        "    sentences=tokenized_docs,\n",
        "    vector_size=50,\n",
        "    window=5,\n",
        "    min_count=1,\n",
        "    workers=2\n",
        ")\n",
        "\n",
        "\n",
        "word = \"language\"\n",
        "print(f\"Embedding vector for '{word}':\")\n",
        "print(w2v_model.wv[word])\n",
        "print(\"Vector size:\", len(w2v_model.wv[word]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X230MPGc00PG",
        "outputId": "93444470-3dc1-4829-f1e3-a88029be7571"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding vector for 'language':\n",
            "[-0.01631583  0.0089916  -0.00827415  0.00164907  0.01699724 -0.00892435\n",
            "  0.009035   -0.01357392 -0.00709698  0.01879702 -0.00315531  0.00064274\n",
            " -0.00828126 -0.01536538 -0.00301602  0.00493959 -0.00177605  0.01106732\n",
            " -0.00548595  0.00452013  0.01091159  0.01669191 -0.00290748 -0.01841629\n",
            "  0.0087411   0.00114357  0.01488382 -0.00162657 -0.00527683 -0.01750602\n",
            " -0.00171311  0.00565313  0.01080286  0.01410531 -0.01140624  0.00371764\n",
            "  0.01217773 -0.0095961  -0.00621452  0.01359526  0.00326295  0.00037983\n",
            "  0.00694727  0.00043555  0.01923765  0.01012121 -0.01783478 -0.01408312\n",
            "  0.00180291  0.01278507]\n",
            "Vector size: 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dsnOfCBH00tn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}